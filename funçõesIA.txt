import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import os
import time
from flask import Flask, request, jsonify
from dotenv import load_dotenv
from flask_cors import CORS

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=GOOGLE_API_KEY)

app = Flask(__name__)
CORS(app)

####################################################
### SEÇÃO 1: FUNÇÃO DE CORREÇÃO BASE E UTILITÁRIAS
####################################################

def aplicar_correcoes_base(soup):
    """
    Aplica correções universais.
    (Corrige o 'outline' de foco).
    """
    print("Aplicando correções de base...")
    
    style_tag = soup.find('style')
    if style_tag and 'outline: none' in style_tag.string:
        style_tag.decompose() 
        print("Corrigido (Base): CSS do Outline removido.")
        
    return soup

def modulo_aplicar_estilos_base(soup, new_styles):
    """Função utilitária para injetar estilos CSS no <head>."""
    head = soup.find('head')
    if head:
        new_style_tag = soup.new_tag('style')
        new_style_tag.string = new_styles
        head.append(new_style_tag)
    return soup


####################################################
### SEÇÃO 2: FUNÇÕES DE PERFIL FINAL E MODULAR
####################################################

def aplicar_perfil_visual(soup, config):
    """
    PERFIL VISUAL (Configuração Modular)
    Implementa: Baixa Visão, Cegueira Total, Daltonismo e Sensibilidade à Luz.
    """
    print(f"--- INICIANDO PERFIL VISUAL (MODULAR) ---")
    soup = aplicar_correcoes_base(soup)
    head = soup.find('head')
    if not head: return soup

    styles = ""

    # 1. BAJA VISÃO / AUMENTAR ESCALA
    if config.get("aumentar_escala"):
        styles += "html { font-size: 140% !important; }"
        print("Módulo: Escala ativado.")
        
    # 2. SENSIBILIDADE À LUZ / FILTRO
    if config.get("sensibilidade_luz"):
        styles += "body { filter: sepia(0.2) saturate(0.8) !important; }"
        print("Módulo: Filtro de Luz (Sépia) ativado.")
        
    # 3. DALTONISMO / MUDAR DE COR
    daltonismo_tipo = config.get("daltonismo_tipo")
    if daltonismo_tipo == "protanopia":
        styles += ".btn-success { background-color: #FFA500 !important; border-color: #FFA500 !important; }"
        print("Módulo: Protanopia ativado.")
    elif daltonismo_tipo == "deuteranopia":
        styles += ".btn-success { background-color: #FFFF00 !important; border-color: #FFFF00 !important; color: #000 !important; }"
        print("Módulo: Deuteranopia ativado.")
    
    # Injeta os estilos CSS coletados
    if styles:
        modulo_aplicar_estilos_base(soup, styles)


    # 4. CEGUEIRA TOTAL / ALT-TEXT E NAVEGAÇÃO (IA)
    if config.get("cegueira_total"):
        print("Módulo: Correções estruturais para Leitores de Tela ativadas.")
        
        # A. Alt-Text com Rate Limit (IA)
        api_call_count = 0
        for img in soup.find_all('img'):
            if not img.get('alt'):
                if api_call_count > 0: time.sleep(31) 
                img_url = img.get('src')
                alt_text = get_alt_text_from_ai(img_url) 
                img['alt'] = alt_text
                api_call_count += 1

        # B. Corrigir Estrutura para Text-to-Speech
        botao_div = soup.find('div', class_='btn-primary')
        if botao_div:
            botao_div['role'] = 'button'; botao_div['tabindex'] = '0'
        for input_tag in soup.find_all(['input', 'textarea']):
            if not input_tag.has_attr('aria-label') and input_tag.get('placeholder'):
                input_tag['aria-label'] = input_tag.get('placeholder')

    print("Concluído: Perfil Visual Modular aplicado.")
    return soup

def aplicar_perfil_auditivo(soup, config):
    """
    CONDIÇÃO: AUDITIVO (Surdez, Hipersensibilidade a som).
    """
    print("--- INICIANDO PERFIL AUDITIVO (MODULAR) ---")
    soup = aplicar_correcoes_base(soup)

    # 1. TRANSCRIÇÃO (IA)
    if config.get("transcricao_surdez"):
        print("Módulo: Transcrição de Áudio (IA) ativado.")
        for video_tag in soup.find_all('video'):
            source_tag = video_tag.find('source')
            if source_tag and source_tag.get('src'):
                video_url = source_tag.get('src')
                transcription_text = get_transcription_from_ai(video_url)
                
                transcription_div = soup.new_tag('div', **{'class': 'alert alert-info mt-2', 'role': 'status'})
                transcription_div.append(BeautifulSoup(f"<p class='fw-bold'>Transcrição (IA):</p><p>{transcription_text}</p>", 'html.parser'))
                
                video_parent_div = video_tag.parent
                if video_parent_div:
                    video_parent_div.insert_after(transcription_div)
    
    # 2. DESATIVAR SOM E VÍDEO AUTOMÁTICO (Hipersensibilidade)
    if config.get("desativar_autoplay"):
        for video_tag in soup.find_all('video'):
            video_tag['autoplay'] = 'false'
            video_tag['muted'] = 'true'
        print("Módulo: Autoplay desativado.")
        
    return soup

def aplicar_perfil_cognitivo(soup, config):
    """
    CONDIÇÃO: COGNITIVO (TDAH, Seniores, Dislexia, Hipersensibilidade, Cognição).
    """
    print("--- INICIANDO PERFIL COGNITIVO (MODULAR) ---")
    soup = aplicar_correcoes_base(soup)
    head = soup.find('head')
    if not head: return soup
    
    # 1. SIMPLIFICAÇÃO DE TEXTO (IA)
    if config.get("simplificar_texto"):
        paragrafo = soup.find('p', class_='lead')
        if paragrafo and paragrafo.string:
            paragrafo.string = get_simplified_text_from_ai(paragrafo.string)
            print("Módulo: Texto simplificado (IA) ativado.")

    # 2. BARRA DE PROGRESSO (TDAH)
    if config.get("barra_progresso"):
        body = soup.find('body')
        if body:
            progress_bar = BeautifulSoup("""<div style="position: sticky; top: 0; width: 100%; height: 8px; background-color: #ddd; z-index: 1000;" role="progressbar" aria-valuenow="33" aria-valuemin="0" aria-valuemax="100"><div style="width: 33%; height: 100%; background-color: #4CAF50; transition: width 0.3s;"></div></div>""", 'html.parser')
            body.insert(0, progress_bar)
            print("Módulo: Barra de progresso adicionada.")
        
    # 3. ESTILOS DE FOCO E SENSIBILIDADE
    css_estilos = ""
    if config.get("destaque_botoes"):
        css_estilos += ".btn { box-shadow: 0 0 10px rgba(0, 255, 255, 0.8) !important; font-weight: bold !important; }"
        print("Módulo: Destaque de botões ativado.")
        
    if config.get("cores_neutras"):
        css_estilos += ".btn-primary { background-color: #000080 !important; } .btn-primary, .btn-success { filter: grayscale(0.2); }"
        print("Módulo: Cores neutras ativadas.")

    if css_estilos:
        soup = modulo_aplicar_estilos_base(soup, css_estilos)

    return soup

# --- FUNÇÕES DE MÍDIA ADICIONAIS ---

def aplicar_perfil_narracao_cegos(soup):
    # ... (Manter a função de narração de vídeo aqui, ela é um módulo único de IA)
    print("--- PERFIL NARRAÇÃO (AUDIODESCRIÇÃO) ---")
    soup = aplicar_correcoes_base(soup)
    for video_tag in soup.find_all('video'):
        source_tag = video_tag.find('source')
        if source_tag and source_tag.get('src'):
            video_url = source_tag.get('src')
            description_text = get_visual_description_from_ai(video_url)
            
            desc_div = soup.new_tag('div', **{'class': 'alert alert-warning mt-2', 'role': 'status'})
            desc_div.append(BeautifulSoup(f"<p class='fw-bold'>Narração (IA):</p><p>{description_text}</p>", 'html.parser'))
            
            video_parent_div = video_tag.parent
            if video_parent_div:
                video_parent_div.insert_after(desc_div)
    return soup


####################################################
### SEÇÃO 3: FUNÇÕES DE IA (O "CÉREBRO")
####################################################

def get_alt_text_from_ai(image_url):
    try:
        response = requests.get(image_url)
        response.raise_for_status() 
        image_part = {
            "mime_type": response.headers['Content-Type'],
            "data": response.content
        }
        model = genai.GenerativeModel('models/gemini-2.5-pro') 
        prompt = """Descreva esta imagem para um usuário de leitor de tela cego. 
                    Seja conciso, no máximo 10 palavras. Responda em português.
                    NÃO inclua nenhuma frase de confirmação ou introdução. 
                    Forneça APENAS a descrição."""
        response = model.generate_content([prompt, image_part])
        print(f"API de Visão OK: {response.text.strip()}")
        return response.text.strip()
    except Exception as e:
        print(f"ERRO na API de Visão para {image_url}: {e}")
        return "Erro ao gerar descrição pela IA"

def get_simplified_text_from_ai(text):
    try:
        model = genai.GenerativeModel('models/gemini-2.5-flash')
        prompt = """Simplifique o texto a seguir para uma pessoa com dislexia ou dificuldade cognitiva. 
                    Use frases curtas e diretas. Responda em português.
                    NÃO inclua nenhuma frase de confirmação ou introdução.
                    Forneça APENAS o texto simplificado."""
        response = model.generate_content(prompt)
        print(f"API de Texto OK: Texto simplificado.")
        return response.text.strip()
    except Exception as e:
        print(f"ERRO na API de Texto: {e}")
        return text 

def get_video_ai_response(video_url, task_prompt):
    local_filename = f"temp_video_{int(time.time())}.mp4"
    video_file = None 
    try:
        print(f"Baixando vídeo para tarefa: {video_url} ...")
        with requests.get(video_url, stream=True) as r:
            r.raise_for_status()
            with open(local_filename, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192): 
                    f.write(chunk)
        print("Download concluído.")

        print("Enviando vídeo para a IA...")
        video_file = genai.upload_file(path=local_filename, display_name="Hackathon Video")
        print(f"Upload iniciado. ID: {video_file.name}. Aguardando processamento...")

        while video_file.state.name == "PROCESSING":
            print("Vídeo ainda está processando... aguardando 5 segundos.")
            time.sleep(5)
            video_file = genai.get_file(video_file.name)

        if video_file.state.name != "ACTIVE":
            raise Exception(f"Processamento do arquivo falhou no servidor. Estado: {video_file.state.name}")
        
        print("Vídeo está 'ACTIVE'. Solicitando IA...")
        model = genai.GenerativeModel('models/gemini-2.5-pro')
        response = model.generate_content([task_prompt, video_file])
        
        print("Limpando arquivos temporários...")
        genai.delete_file(video_file.name) 
        os.remove(local_filename) 
        print(f"API de Vídeo OK: Texto gerado.")
        return response.text.strip()
    except Exception as e:
        print(f"ERRO GIGANTE na API de Vídeo: {e}")
        if os.path.exists(local_filename):
            os.remove(local_filename)
        if video_file and video_file.name:
             try:
                 genai.delete_file(video_file.name)
             except Exception as cleanup_e:
                 pass
        return "Erro ao processar o vídeo."

def get_transcription_from_ai(video_url):
    prompt = """Ouça o áudio deste vídeo e transcreva exatamente o que é dito. 
                Se não houver fala, descreva os sons (ex: '[música instrumental]'). 
                Responda em português.
                NÃO inclua nenhuma frase de confirmação ou introdução.
                Forneça APENAS a transcrição."""
    return get_video_ai_response(video_url, prompt)

def get_visual_description_from_ai(video_url):
    prompt = """Você é um narrador de audiodescrição para uma pessoa cega. 
                Assista a este vídeo e descreva apenas as informações visuais que não são óbvias pelo som. 
                O que está acontecendo visualmente? Responda em português.
                NÃO inclua nenhuma frase de confirmação ou introdução.
                Forneça APENAS a descrição."""
    return get_video_ai_response(video_url, prompt)


####################################################
### SEÇÃO 4: O SERVIDOR FLASK
####################################################

@app.route("/")
def hello():
    # página inicial simples para sabermos que o servidor está no ar
    return "Servidor do Adaptador de Acessibilidade está no ar!"

@app.route("/adaptar", methods=["POST"])
def handle_adaptation():
    print("\n--- REQUISIÇÃO RECEBIDA NO ENDPOINT /adaptar ---")
    
    data = request.json
    perfil = data.get("profile")
    html_quebrado = data.get("html_content")
    
    # O objeto 'config' deve ser um dicionário para as opções modulares
    config = data.get("config", {}) 
    
    if not html_quebrado or not perfil:
        return jsonify({"erro": "Faltando 'html_content' ou 'profile'"}), 400

    # usa a lógica do seu adaptador
    soup = BeautifulSoup(html_quebrado, 'html.parser')
    html_corrigido = ""

    try:
        # Chama a função de perfil apropriada
        if perfil == "visual":
            # Passa o objeto config (que pode ter 'aumentar_escala', 'daltonismo_tipo', etc)
            soup_corrigido = aplicar_perfil_visual(soup, config)
        elif perfil == "auditivo":
            soup_corrigido = aplicar_perfil_auditivo(soup, config)
        elif perfil == "cognitivo":
            soup_corrigido = aplicar_perfil_cognitivo(soup, config)
        elif perfil == "narracao_cegos":
            # Narração não precisa de config adicional, mas a recebe.
            soup_corrigido = aplicar_perfil_narracao_cegos(soup)
        elif perfil == "alto_contraste":
            # Criamos um perfil de alto contraste de emergência (não modular)
            config_alto_contraste = {"aumentar_escala": True, "daltonismo_tipo": "alto_contraste_simples", "sensibilidade_luz": True}
            soup_corrigido = aplicar_perfil_visual(soup, config_alto_contraste)
        else:
            return jsonify({"erro": f"Perfil '{perfil}' desconhecido"}), 400
        
        html_corrigido = str(soup_corrigido)
        
        print(f"--- REQUISIÇÃO CONCLUÍDA (Perfil: {perfil}) ---")
        return jsonify({"html_corrigido": html_corrigido})

    except Exception as e:
        print(f"ERRO 500 - FALHA GERAL NO PROCESSAMENTO: {e}")
        return jsonify({"erro": f"Erro interno do servidor: {e}"}), 500


####################################################
### SEÇÃO 5: EXECUÇÃO PRINCIPAL (Para rodar o servidor)
####################################################

if __name__ == "__main__":
    # Remove a lógica antiga de criar arquivos
    # e inicia o servidor Flask
    print("Iniciando o servidor Flask em http://127.0.0.1:5000")
    app.run(debug=True, port=5000)